{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88312d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 1 faces!\n",
      "Found 0 faces!\n",
      "Found 1 faces!\n",
      "Found 0 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 1 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 0 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 2 faces!\n",
      "Found 0 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def blur(img,k):\n",
    "    h,w = img.shape[:2]\n",
    "    kh,kw = h//k,w//k\n",
    "    if kh%2==0:\n",
    "        kh-=1\n",
    "    if kw%2==0:\n",
    "        kw-=1\n",
    "    img = cv2.GaussianBlur(img,ksize=(kh,kw),sigmaX=0)\n",
    "    return img\n",
    "def pixelate_face(image, blocks=10):\n",
    "    # divide the input image into NxN blocks\n",
    "    (h, w) = image.shape[:2]\n",
    "    xSteps = np.linspace(0, w, blocks + 1, dtype=\"int\")\n",
    "    ySteps = np.linspace(0, h, blocks + 1, dtype=\"int\")\n",
    "    # loop over the blocks in both the x and y direction\n",
    "    for i in range(1, len(ySteps)):\n",
    "        for j in range(1, len(xSteps)):\n",
    "            # compute the starting and ending (x, y)-coordinates\n",
    "            # for the current block\n",
    "            startX = xSteps[j - 1]\n",
    "            startY = ySteps[i - 1]\n",
    "            endX = xSteps[j]\n",
    "            endY = ySteps[i]\n",
    "            # extract the ROI using NumPy array slicing, compute the\n",
    "            # mean of the ROI, and then draw a rectangle with the\n",
    "            # mean RGB values over the ROI in the original image\n",
    "            roi = image[startY:endY, startX:endX]\n",
    "            (B, G, R) = [int(x) for x in cv2.mean(roi)[:3]]\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                (B, G, R), -1)\n",
    "    # return the pixelated blurred image\n",
    "    return image\n",
    "factor = 3    \n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "while 1:\n",
    "    ret,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30, 30))\n",
    "    #flags = cv2.CV_HAAR_SCALE_IMAGE\n",
    "           \n",
    "\n",
    "    print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Drawing a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame[y:y+h,x:x+w] = pixelate_face(blur(frame[y:y+h,x:x+w],factor))\n",
    "    cv2.imshow('Live',frame)\n",
    "    if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bea479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e387110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1157ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101976a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc603c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec094dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fa7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c0b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01709520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce4975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fecb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e439fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7834c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHIDAM~1\\AppData\\Local\\Temp/ipykernel_11756/2937119074.py:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces==():\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    faces = faceCascade.detectMultiScale(img,1.2,4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        # To make a face blurred\n",
    "        ROI = img[y:y+h, x:x+w]\n",
    "        blur = cv2.GaussianBlur(ROI, (91,91),0) \n",
    "        # Insert ROI back into image\n",
    "        img[y:y+h, x:x+w] = blur\n",
    "\n",
    "        # To make a bounding box #*(Not Necessary)\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),4)\n",
    "    if faces==():\n",
    "        cv2.putText(img,'No Face Found!',(20,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255))\n",
    "    cv2.imshow('Face Blur',img)\n",
    "    if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "        break\n",
    "# Turn camera off        \n",
    "cap.release()\n",
    "# Close camera window\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8b0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bb949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4148db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n",
      "Found 1 faces!\n"
     ]
    }
   ],
   "source": [
    "# Importing the CV2 library\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "while(True):\n",
    "# Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Converting the captures into grayscale images\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detecting faces in the web-cam stream\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    #flags = cv2.CV_HAAR_SCALE_IMAGE\n",
    "            )\n",
    "\n",
    "    print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Drawing a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # Displaying the resulting frame\n",
    "    cv2.imshow('Window', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cc0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b377a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d69273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d26dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c7d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e197b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7f2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "  \n",
    "# to detect the face of the human\n",
    "cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "  \n",
    "# VideoCapture is a function, to capture\n",
    "# video from the camera attached to system\n",
    "# You can pass either 0 or 1\n",
    "# 0 for laptop webcam\n",
    "# 1 for external webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "  \n",
    "# a while loop to run infinite times,\n",
    "# to capture infinite number of frames for video\n",
    "# because a video is a combination of frames\n",
    "while True:\n",
    "    \n",
    "    # capture the latest frame from the video\n",
    "    check, frame = video_capture.read()\n",
    "  \n",
    "    # convert the frame into grayscale(shades of black & white)\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "    # detect multiple faces in a captured frame\n",
    "    # scaleFactor: Parameter specify how much the\n",
    "    # image sizeis reduced at each image scale.\n",
    "    # minNeighbors: Parameter specify how many\n",
    "    # neighbours each rectangle should have to retain it.\n",
    "    # rectangle consists the detect object.\n",
    "    # Here the object is the face.\n",
    "    face = cascade.detectMultiScale(\n",
    "        gray_image, scaleFactor=2.0, minNeighbors=4)\n",
    "  \n",
    "    for x, y, w, h in face:\n",
    "  \n",
    "        # draw a border around the detected face. \n",
    "        # (here border color = green, and thickness = 3)\n",
    "        image = cv2.rectangle(frame, (x, y), (x+w, y+h), \n",
    "                              (0, 255, 0), 3)\n",
    "  \n",
    "        # blur the face which is in the rectangle\n",
    "        image[y:y+h, x:x+w] = cv2.medianBlur(image[y:y+h, x:x+w],\n",
    "                                             35)\n",
    "  \n",
    "    # show the blurred face in the video\n",
    "    cv2.imshow('face blurred', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "  \n",
    "    # This statement just runs once per frame.\n",
    "    # Basically, if we get a key, and that key is a q,\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "  \n",
    "# we will exit the while loop with a break,\n",
    "# which then runs:\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e3a009",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy.prototxt.txt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHIDAM~1\\AppData\\Local\\Temp/ipykernel_16012/819952629.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mwebcam_masking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\CHIDAM~1\\AppData\\Local\\Temp/ipykernel_16012/819952629.py\u001b[0m in \u001b[0;36mwebcam_masking\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodelFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"res10_300x300_ssd_iter_140000.caffemodel\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mconfigFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"deploy.prototxt.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m## Initialize Webcam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy.prototxt.txt\" in function 'cv::dnn::ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def webcam_masking():\n",
    "\n",
    "    modelFile = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "    configFile = \"deploy.prototxt.txt\"\n",
    "    net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "    ## Initialize Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ## Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            cv2.resize(frame, (300, 300)),1.0, (300, 300), (104.0, 117.0, 123.0)\n",
    "            )\n",
    "\n",
    "        net.setInput(blob)\n",
    "        faces = net.forward()\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Set kernel Width and Height of OpenCV Gaussian Blur module. \n",
    "        # The larger the resolution, the larger should the kernel dimensions be\n",
    "        kernel_width = (width//5) if (width//5)%2==1 else (width//5)+1\n",
    "        kernel_height = (height//5) if (height//5)%2==1 else (height//5)+1\n",
    "\n",
    "            ## Detect faces in frame\n",
    "        for i in range(faces.shape[2]):\n",
    "            confidence = faces[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                box = faces[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                (x, y, x1, y1) = box.astype(\"int\")\n",
    "\n",
    "                face = frame[y:y1,x:x1]\n",
    "\n",
    "                # create a mask image of the same shape face, filled with 0s (black color)\n",
    "                mask = np.zeros_like(face)\n",
    "                rows, cols,_ = mask.shape\n",
    "\n",
    "                # create a white filled ellipse\n",
    "                mask=cv2.ellipse(\n",
    "                    mask, center=(int(cols/2), int(rows/2)), axes=(int(cols/2),int(rows/2)), \n",
    "                    angle=0, startAngle=0, endAngle=360, color=(255,255,255), thickness=-1\n",
    "                    )\n",
    "\n",
    "                blur = cv2.GaussianBlur(face, (kernel_width, kernel_height), 0)\n",
    "                blurred_face = np.where(mask==np.array([255, 255, 255]), blur, face)\n",
    "\n",
    "                frame[y:y1,x:x1] = blurred_face\n",
    "\n",
    "        ## Display the resulting frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    webcam_masking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee40130d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    for (x, y, w, h) in faces:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    faces = faceCascade.detectMultiScale(img,1.2,4)\n",
    "    # Detecting faces in the web-cam stream\n",
    "\tfaces = faceCascade.detectMultiScale(\n",
    "\tgray,\n",
    "\t\tscaleFactor=1.1,\n",
    "\t\tminNeighbors=5,\n",
    "\t\tminSize=(30, 30)\n",
    "\t\t#flags = cv2.CV_HAAR_SCALE_IMAGE\n",
    "\t)\n",
    "\n",
    "\tprint(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # To make a face blurred\n",
    "        ROI = img[y:y+h, x:x+w]\n",
    "        blur = cv2.GaussianBlur(ROI, (91,91),0) \n",
    "        # Insert ROI back into image\n",
    "        img[y:y+h, x:x+w] = blur\n",
    "\n",
    "        # To make a bounding box #*(Not Necessary)\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),4)\n",
    "    if faces==():\n",
    "        cv2.putText(img,'No Face Found!',(20,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255))\n",
    "    cv2.imshow('Face Blur',img)\n",
    "    if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "        break\n",
    "# Turn camera off        \n",
    "cap.release()\n",
    "# Close camera window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391db5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple Face Blur on a live webcam video streams using Gausian Blur\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "video_cam = cv2.VideoCapture(0)\n",
    "# Haar Cascade to detect frontal faces\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "while True:\n",
    "    ret, image_frame = video_cam.read()\n",
    "    # Detect faces in the Webcam Video Stream\n",
    "    faces = face_cascade.detectMultiScale(image_frame,1.3,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        # Enclose inside a blue rectangular box\n",
    "        cv2.rectangle(image_frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        # Select only detected face portion for Blur\n",
    "        face_color = image_frame[y:y + h, x:x + w]\n",
    "        # Blur the Face with Gaussian Blur of Kernel Size 51*51\n",
    "        blur = cv2.GaussianBlur(face_color, (51, 51), 0)\n",
    "        image_frame[y:y + h, x:x + w] = blur\n",
    "    # Display the Blurred Faces\n",
    "    cv2.imshow('Detected Face',image_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e490ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def blur(img,k):\n",
    "    h,w = img.shape[:2]\n",
    "    kh,kw = h//k,w//k\n",
    "    if kh%2==0:\n",
    "        kh-=1\n",
    "    if kw%2==0:\n",
    "        kw-=1\n",
    "    img = cv2.GaussianBlur(img,ksize=(kh,kw),sigmaX=0)\n",
    "    return img\n",
    "def pixelate_face(image, blocks=10):\n",
    "    # divide the input image into NxN blocks\n",
    "    (h, w) = image.shape[:2]\n",
    "    xSteps = np.linspace(0, w, blocks + 1, dtype=\"int\")\n",
    "    ySteps = np.linspace(0, h, blocks + 1, dtype=\"int\")\n",
    "    # loop over the blocks in both the x and y direction\n",
    "    for i in range(1, len(ySteps)):\n",
    "        for j in range(1, len(xSteps)):\n",
    "            # compute the starting and ending (x, y)-coordinates\n",
    "            # for the current block\n",
    "            startX = xSteps[j - 1]\n",
    "            startY = ySteps[i - 1]\n",
    "            endX = xSteps[j]\n",
    "            endY = ySteps[i]\n",
    "            # extract the ROI using NumPy array slicing, compute the\n",
    "            # mean of the ROI, and then draw a rectangle with the\n",
    "            # mean RGB values over the ROI in the original image\n",
    "            roi = image[startY:endY, startX:endX]\n",
    "            (B, G, R) = [int(x) for x in cv2.mean(roi)[:3]]\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                (B, G, R), -1)\n",
    "    # return the pixelated blurred image\n",
    "    return image\n",
    "factor = 3    \n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "while 1:\n",
    "    ret,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame[y:y+h,x:x+w] = pixelate_face(blur(frame[y:y+h,x:x+w],factor))\n",
    "    cv2.imshow('Live',frame)\n",
    "    if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
